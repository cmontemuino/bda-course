{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e270646a",
   "metadata": {},
   "source": [
    "# Introduction to the DataFrame API\n",
    "\n",
    "In this section, we will introduce the [DataFrame and Dataset APIs](https://spark.apache.org/docs/latest/sql-programming-guide.html).\n",
    "\n",
    "We will use a small subset from the [Record Linkage Comparison Data Set](https://archive.ics.uci.edu/ml/datasets/record+linkage+comparison+patterns), borrowed from UC Irvine Machine Learning Repository. It consists of several CSV files with match scores for patients in a Germany hospital, but we will use only one of them for the sake of simplicity. Please consult {cite:p}`schmidtmann2009evaluation` and {cite:p}`sariyar2011controlling` for more details regarding the data sets and research. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0a219",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Setup a `SparkSession` to work with the Dataset and DataFrame API\n",
    "- Unzip the `scores.zip` file located under `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(\"intro-to-df\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "# Avoid polluting the console with warning messages\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba91de",
   "metadata": {},
   "source": [
    "### Create a SparkSession to work with the DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55551972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696fa258",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(SparkSession)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e10026",
   "metadata": {},
   "source": [
    "### Unzip the scores file, if it was not done already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d936fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "scores_zip = path.join(\"data\", \"scores.zip\")\n",
    "scores_csv = path.join(\"data\", \"scores.csv\")\n",
    "\n",
    "%set_env SCORES_ZIP=$scores_zip\n",
    "%set_env SCORES_CSV=$scores_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "command -v unzip >/dev/null 2>&1 || { echo >&2 \"unzip command is not installed. Aborting.\"; exit 1; }\n",
    "[[ -f \"$SCORES_CSV\" ]] && { echo \"file data/$SCORES_CSV already exist. Skipping.\"; exit 0; }\n",
    "\n",
    "[[ -f \"$SCORES_ZIP\" ]] || { echo \"file data/$SCORES_ZIP does not exist. Aborting.\"; exit 1; }\n",
    "\n",
    "echo \"Unzip file $SCORES_ZIP\"\n",
    "unzip \"$SCORES_ZIP\" -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head \"$SCORES_CSV\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25100f59",
   "metadata": {},
   "source": [
    "## Loading the Scores CSV file into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23761d96",
   "metadata": {},
   "source": [
    "We are going to use the Reader API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4159f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(spark.read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f24108",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(spark.read.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = spark.read.csv(scores_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(scores.show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8dfda1",
   "metadata": {},
   "source": [
    "We can look at the head of the DataFrame calling the `show` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce251f3",
   "metadata": {},
   "source": [
    "scores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350dad7",
   "metadata": {},
   "source": [
    "**Can anyone spot what's wrong with the above data?**\n",
    "\n",
    "- Question marks\n",
    "- Column names\n",
    "- `Float` and `Int` in the same column\n",
    "\n",
    "Let's check the schema of our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(scores.printSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cd5d2",
   "metadata": {},
   "source": [
    "**Why everythin is a `String`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6b185",
   "metadata": {},
   "source": [
    "### Managing Schema and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"nullValue\", \"?\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .csv(scores_csv)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6076282",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6397e5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd4cf67b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":style: unsrt\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda-labs",
   "language": "python",
   "name": "bda-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
