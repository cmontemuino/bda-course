{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de418d8a",
   "metadata": {},
   "source": [
    "# Introduction to the DataFrame API\n",
    "\n",
    "In this section, we will introduce the [DataFrame and Dataset APIs](https://spark.apache.org/docs/latest/sql-programming-guide.html).\n",
    "\n",
    "We will use a small subset from the [Record Linkage Comparison Data Set](https://archive.ics.uci.edu/ml/datasets/record+linkage+comparison+patterns), borrowed from UC Irvine Machine Learning Repository. It consists of several CSV files with match scores for patients in a Germany hospital, but we will use only one of them for the sake of simplicity. Please consult {cite:p}`schmidtmann2009evaluation` and {cite:p}`sariyar2011controlling` for more details regarding the data sets and research. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45285dd9",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Setup a `SparkSession` to work with the Dataset and DataFrame API\n",
    "- Unzip the `scores.zip` file located under `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3049374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/07 13:23:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/07 13:23:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(\"intro-to-df\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "# Avoid polluting the console with warning messages\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47aaad",
   "metadata": {},
   "source": [
    "### Create a SparkSession to work with the DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230a0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bfe700",
   "metadata": {},
   "source": [
    "### Unzip the scores file, if it was not done already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be51854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCORES_ZIP=data/scores.zip\n",
      "env: SCORES_CSV=data/scores.csv\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "scores_zip = path.join(\"data\", \"scores.zip\")\n",
    "scores_csv = path.join(\"data\", \"scores.csv\")\n",
    "\n",
    "%set_env SCORES_ZIP=$scores_zip\n",
    "%set_env SCORES_CSV=$scores_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cadbc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file data/data/scores.csv already exist. Skipping.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "command -v unzip >/dev/null 2>&1 || { echo >&2 \"unzip command is not installed. Aborting.\"; exit 1; }\n",
    "[[ -f \"$SCORES_CSV\" ]] && { echo \"file data/$SCORES_CSV already exist. Skipping.\"; exit 0; }\n",
    "\n",
    "[[ -f \"$SCORES_ZIP\" ]] || { echo \"file data/$SCORES_ZIP does not exist. Aborting.\"; exit 1; }\n",
    "\n",
    "echo \"Unzip file $SCORES_ZIP\"\n",
    "unzip \"$SCORES_ZIP\" -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4befecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\r\n",
      "37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\r\n",
      "39086,47614,1,?,1,?,1,1,1,1,1,TRUE\r\n",
      "70031,70237,1,?,1,?,1,1,1,1,1,TRUE\r\n",
      "84795,97439,1,?,1,?,1,1,1,1,1,TRUE\r\n",
      "36950,42116,1,?,1,1,1,1,1,1,1,TRUE\r\n",
      "42413,48491,1,?,1,?,1,1,1,1,1,TRUE\r\n",
      "25965,64753,1,?,1,?,1,1,1,1,1,TRUE\r\n",
      "49451,90407,1,?,1,?,1,1,1,1,0,TRUE\r\n",
      "39932,40902,1,?,1,?,1,1,1,1,1,TRUE\r\n"
     ]
    }
   ],
   "source": [
    "! head \"$SCORES_CSV\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd1bf3",
   "metadata": {},
   "source": [
    "## Loading the Scores CSV file into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7be399",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":style: unsrt\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda-labs",
   "language": "python",
   "name": "bda-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
